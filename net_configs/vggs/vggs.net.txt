Name           : Layer          (n, c, h, w)         (s_w, s_h, p_w, p_h)

input          : Input          
conv1          : Convolution    (96, 3, 7, 7)        (2, 2, 0, 0)
relu1          : ReLU           
norm1          : LRN            
pool1          : Pooling        (type: MAX, 3, 3)    (3, 3, 0, 0)
conv2          : Convolution    (256, 96, 5, 5)      (1, 1, 0, 0)
relu2          : ReLU           
pool2          : Pooling        (type: MAX, 2, 2)    (2, 2, 0, 0)
conv3          : Convolution    (512, 256, 3, 3)     (1, 1, 1, 1)
relu3          : ReLU           
conv4          : Convolution    (512, 512, 3, 3)     (1, 1, 1, 1)
relu4          : ReLU           
conv5          : Convolution    (512, 512, 3, 3)     (1, 1, 1, 1)
relu5          : ReLU           
pool5          : Pooling        (type: MAX, 3, 3)    (3, 3, 0, 0)
fc6            : InnerProduct   (4096, 18432)       
relu6          : ReLU           
drop6          : Dropout        
fc7            : InnerProduct   (4096, 4096)        
relu7          : ReLU           
drop7          : Dropout        
fc8            : InnerProduct   (1000, 4096)        
prob           : Softmax        


FeatureMaps    :  (b, c, h, w)

data           :  (1, 3, 224, 224)
conv1          :  (1, 96, 109, 109)
norm1          :  (1, 96, 109, 109)
pool1          :  (1, 96, 37, 37)
conv2          :  (1, 256, 33, 33)
pool2          :  (1, 256, 17, 17)
conv3          :  (1, 512, 17, 17)
conv4          :  (1, 512, 17, 17)
conv5          :  (1, 512, 17, 17)
pool5          :  (1, 512, 6, 6)
fc6            :  (1, 4096)
fc7            :  (1, 4096)
fc8            :  (1, 1000)
prob           :  (1, 1000)
