Name           : Layer          (n, c, h, w)         (s_w, s_h, p_w, p_h)

data           : Input          
conv1          : Convolution    (96, 3, 11, 11)      (4, 4, 4, 4)
relu1          : ReLU           
norm1          : LRN            
pool1          : Pooling        (type: MAX, 3, 3)    (2, 2, 0, 0)
conv2          : Convolution    (256, 48, 5, 5)      (1, 1, 2, 2)
relu2          : ReLU           
norm2          : LRN            
pool2          : Pooling        (type: MAX, 3, 3)    (2, 2, 0, 0)
conv3          : Convolution    (384, 256, 3, 3)     (1, 1, 1, 1)
relu3          : ReLU           
conv4          : Convolution    (384, 192, 3, 3)     (1, 1, 1, 1)
relu4          : ReLU           
conv5          : Convolution    (256, 192, 3, 3)     (1, 1, 1, 1)
relu5          : ReLU           
pool5          : Pooling        (type: MAX, 3, 3)    (2, 2, 0, 0)
fc6_fact1      : InnerProduct   
fc6_fact2      : InnerProduct   
relu6          : ReLU           
drop6          : Dropout        
fc7_fact1      : InnerProduct   
fc7_fact2      : InnerProduct   
relu7          : ReLU           
drop7          : Dropout        
fc8            : InnerProduct   
prob           : Softmax        

Blobs:
data           :  (1, 3, 224, 224)
conv1          :  (1, 96, 56, 56)
norm1          :  (1, 96, 56, 56)
pool1          :  (1, 96, 28, 28)
conv2          :  (1, 256, 28, 28)
norm2          :  (1, 256, 28, 28)
pool2          :  (1, 256, 14, 14)
conv3          :  (1, 384, 14, 14)
conv4          :  (1, 384, 14, 14)
conv5          :  (1, 256, 14, 14)
pool5          :  (1, 256, 7, 7)
fc6_fact1      :  (1, 445)
fc6_fact2      :  (1, 4096)
fc7_fact1      :  (1, 406)
fc7_fact2      :  (1, 4096)
fc8            :  (1, 1000)
prob           :  (1, 1000)
