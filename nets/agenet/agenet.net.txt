Name           : Layer          (n, c, h, w)         (s_w, s_h, p_w, p_h)

input          : Input          
conv1          : Convolution    (96, 3, 7, 7)        (4, 4, 0, 0)
relu1          : ReLU           
pool1          : Pooling        (type: MAX, 3, 3)    (2, 2, 0, 0)
norm1          : LRN            
conv2          : Convolution    (256, 96, 5, 5)      (1, 1, 2, 2)
relu2          : ReLU           
pool2          : Pooling        (type: MAX, 3, 3)    (2, 2, 0, 0)
norm2          : LRN            
conv3          : Convolution    (384, 256, 3, 3)     (1, 1, 1, 1)
relu3          : ReLU           
pool5          : Pooling        (type: MAX, 3, 3)    (2, 2, 0, 0)
fc6            : InnerProduct   (512, 18816)        
relu6          : ReLU           
drop6          : Dropout        
fc7            : InnerProduct   (512, 512)          
relu7          : ReLU           
drop7          : Dropout        
fc8            : InnerProduct   (8, 512)            
prob           : Softmax        


FeatureMaps    :  (b, c, h, w)

data           :  (1, 3, 227, 227)
conv1          :  (1, 96, 56, 56)
pool1          :  (1, 96, 28, 28)
norm1          :  (1, 96, 28, 28)
conv2          :  (1, 256, 28, 28)
pool2          :  (1, 256, 14, 14)
norm2          :  (1, 256, 14, 14)
conv3          :  (1, 384, 14, 14)
pool5          :  (1, 384, 7, 7)
fc6            :  (1, 512)
fc7            :  (1, 512)
fc8            :  (1, 8)
prob           :  (1, 8)
